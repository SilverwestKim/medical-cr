con=read_html(urlk)
read_html(link[2])
link
x=read_html(link[1],encodin= 'UTF-8')
x=read_html(link[1],encodin= 'EUC-KR')
x
x=read_html(link[1],encoding= 'EUC-KR')
x=read_html(link[2],encoding= 'EUC-KR')
suburl[i]= read_html(link[i],encoding = 'EUC-KR')
for (i in length(link)){
suburl[i]= read_html(link[i],encoding = 'EUC-KR')
}
for (i in 1:5{
suburl=c()
for (i in 1:5){
suburl[i]= read_html(link[i],encoding = 'EUC-KR')
}
x=read_html(link[1])
x=read_html(link[1],encoding = 'EUC-KR')
x=read_html(link[1],encoding = 'UTF-8')
?read_html
x=read_html(link[2],encoding = 'UTF-8')
x=read_html(link[3],encoding = 'UTF-8')
x=read_html(link[4],encoding = 'UTF-8')
x=read_html(link[5],encoding = 'UTF-8')
x=read_html(link[6],encoding = 'UTF-8')
x=readLines(link[6])
x=readLines(link[1])
x
class(x)
length(x)
(list=ls())
rm(list=ls())
url="https://search.naver.com/search.naver?sm=tab_dts&where=news&query=+%22%EB%B3%91%EC%9B%90%22+%22%ED%99%98%EC%9E%90%EC%95%88%EC%A0%84%22+-%ED%8C%8C%EC%97%85+-%EB%B3%B4%ED%97%98+-%EC%B9%98%EB%A7%A4+-%EC%BC%80%EC%9D%B4%ED%81%AC+-%ED%8F%AD%ED%96%89+-%EB%9D%BC%EC%9D%B4%ED%94%84+-%EB%B0%98%EB%A0%A4%EA%B2%AC+-%ED%97%8C%ED%98%88+-%EB%AF%B8%EC%9A%A9+-%EC%BB%A8%EC%84%A4%ED%8C%85+&oquery=%22%EB%B3%91%EC%9B%90%22+%22%ED%99%98%EC%9E%90%EC%95%88%EC%A0%84%22+-%22%EC%8B%A0%EA%B8%B0%EC%88%A0+%EA%B0%9C%EB%B0%9C%22+-%22%EC%8B%A0%EC%A0%9C%ED%92%88+%EC%B6%9C%EC%8B%9C%22+-%ED%8C%8C%EC%97%85+-%EB%B3%B4%ED%97%98+-%EC%B9%98%EB%A7%A4+-%EC%BC%80%EC%9D%B4%ED%81%AC+-%ED%8F%AD%ED%96%89+-%EB%9D%BC%EC%9D%B4%ED%94%84+-%EB%B0%98%EB%A0%A4%EA%B2%AC+-%ED%97%8C%ED%98%88+-%EB%AF%B8%EC%9A%A9+-%EC%BB%A8%EC%84%A4%ED%8C%85&tqi=TIWrzdpySDlssbyFkqwssssstVs-096592&qdt=1&qdt=1"
cont = read_html(url)
subcont = html_nodes(cont, '.type01')
subc= html_nodes(subcont, 'dt')
subcont1 = html_nodes(subc, 'a')
link = html_attr(subcont1, 'href')
title = html_text(subcont1)
title
link
x=read_html(link[1])
rm(list=ls())
#<병원 + 환자안전>
#"병원" "환자안전"이 정확하게 일치하고 '파업' '보험' '치매' '케이크' '폭행' '라이프' '반려견' '헌혈' '미용' '컨설팅'을 제외한 상세검색 결과
if(!require(dplyr)) install.packages("dplyr"); library(dplyr)
if(!require(rvest)) install.packages("rvest"); library(rvest)
if(!require(stringr)) install.packages("stringr"); library(stringr)
if(!require(httr)) install.packages("httr"); library(httr)
url="https://search.naver.com/search.naver?sm=tab_dts&where=news&query=+%22%EB%B3%91%EC%9B%90%22+%22%ED%99%98%EC%9E%90%EC%95%88%EC%A0%84%22+-%ED%8C%8C%EC%97%85+-%EB%B3%B4%ED%97%98+-%EC%B9%98%EB%A7%A4+-%EC%BC%80%EC%9D%B4%ED%81%AC+-%ED%8F%AD%ED%96%89+-%EB%9D%BC%EC%9D%B4%ED%94%84+-%EB%B0%98%EB%A0%A4%EA%B2%AC+-%ED%97%8C%ED%98%88+-%EB%AF%B8%EC%9A%A9+-%EC%BB%A8%EC%84%A4%ED%8C%85+&oquery=%22%EB%B3%91%EC%9B%90%22+%22%ED%99%98%EC%9E%90%EC%95%88%EC%A0%84%22+-%22%EC%8B%A0%EA%B8%B0%EC%88%A0+%EA%B0%9C%EB%B0%9C%22+-%22%EC%8B%A0%EC%A0%9C%ED%92%88+%EC%B6%9C%EC%8B%9C%22+-%ED%8C%8C%EC%97%85+-%EB%B3%B4%ED%97%98+-%EC%B9%98%EB%A7%A4+-%EC%BC%80%EC%9D%B4%ED%81%AC+-%ED%8F%AD%ED%96%89+-%EB%9D%BC%EC%9D%B4%ED%94%84+-%EB%B0%98%EB%A0%A4%EA%B2%AC+-%ED%97%8C%ED%98%88+-%EB%AF%B8%EC%9A%A9+-%EC%BB%A8%EC%84%A4%ED%8C%85&tqi=TIWrzdpySDlssbyFkqwssssstVs-096592&qdt=1&qdt=1"
#cont = GET(url)
#cont = content(cont)
cont = read_html(url)
subcont = html_nodes(cont, '.type01')
subc= html_nodes(subcont, 'dt')
subcont1 = html_nodes(subc, 'a')
link = html_attr(subcont1, 'href')
title = html_text(subcont1)
link
title
link[3]
x=GET(link[1])
x
a=html_nodes(x,'.content')
a=html_nodes(x,'.contents')
x
x[1]
x[[1]]
x[[2]]
x[[3]]
str_detect(x,"read_body")
which(str_detect(x,"read_body"))
which(str_detect(x,"read_body")==TRUE)
x=readLines(link[1],encoding = 'UTF-8')
index = which(str_detect(x, "<td class=\"\">")==TRUE)
index
str_detect(x, "tbody")==TRUE
which(str_detect(x, "tbody")==TRUE)
x=GET(link[1])
content(x)
content(x)[2]
content(x)[[2]]
content(x)[1]
x[1]
x[2]
html_nodes(x,'.read_body')
x=GET(link[1])
x=html(x)
y=html_nodes(x,'.read_body')
y
te=html_text(x)
te
x
te=html_text(y)
te
rm(list=ls())
if(!require(dplyr)) install.packages("dplyr"); library(dplyr)
if(!require(rvest)) install.packages("rvest"); library(rvest)
if(!require(stringr)) install.packages("stringr"); library(stringr)
if(!require(httr)) install.packages("httr"); library(httr)
url="https://search.naver.com/search.naver?sm=tab_dts&where=news&query=+%22%EB%B3%91%EC%9B%90%22+%22%ED%99%98%EC%9E%90%EC%95%88%EC%A0%84%22+-%ED%8C%8C%EC%97%85+-%EB%B3%B4%ED%97%98+-%EC%B9%98%EB%A7%A4+-%EC%BC%80%EC%9D%B4%ED%81%AC+-%ED%8F%AD%ED%96%89+-%EB%9D%BC%EC%9D%B4%ED%94%84+-%EB%B0%98%EB%A0%A4%EA%B2%AC+-%ED%97%8C%ED%98%88+-%EB%AF%B8%EC%9A%A9+-%EC%BB%A8%EC%84%A4%ED%8C%85+&oquery=%22%EB%B3%91%EC%9B%90%22+%22%ED%99%98%EC%9E%90%EC%95%88%EC%A0%84%22+-%22%EC%8B%A0%EA%B8%B0%EC%88%A0+%EA%B0%9C%EB%B0%9C%22+-%22%EC%8B%A0%EC%A0%9C%ED%92%88+%EC%B6%9C%EC%8B%9C%22+-%ED%8C%8C%EC%97%85+-%EB%B3%B4%ED%97%98+-%EC%B9%98%EB%A7%A4+-%EC%BC%80%EC%9D%B4%ED%81%AC+-%ED%8F%AD%ED%96%89+-%EB%9D%BC%EC%9D%B4%ED%94%84+-%EB%B0%98%EB%A0%A4%EA%B2%AC+-%ED%97%8C%ED%98%88+-%EB%AF%B8%EC%9A%A9+-%EC%BB%A8%EC%84%A4%ED%8C%85&tqi=TIWrzdpySDlssbyFkqwssssstVs-096592&qdt=1&qdt=1"
link = read_html(url) %>% html_nodes('.type01')%>% html_nodes('dt')%>%html_nodes('a')%>%('href')
link = read_html(url) %>% html_nodes('.type01')%>% html_nodes('dt')%>%html_nodes('a')%>%html_nodes('href')
link
link = read_html(url) %>% html_nodes('.type01')%>% html_nodes('dt')%>%html_nodes('a')
link
link = read_html(url) %>% html_nodes('.type01')%>% html_nodes('dt')%>%html_nodes('a')%>%html_attr'href')
link = read_html(url) %>% html_nodes('.type01')%>% html_nodes('dt')%>%html_nodes('a')%>%html_attr('href')
link
title = read_html(url) %>% html_nodes('.type01')%>% html_nodes('dt')%>%html_nodes('a')%>%html_text
title
sublink=link
sublink
x=c()
length(sublink)
y
x=GET(link[1])
x=html(x)
te=html_text(y)
te=html_text(x)
te
x=GET(link[2])
x=html(x)
link[2]
x=GET(link[2])
x=html(x)
?Deprecated
link[3]
x=GET(link[3])
x=html(x)
x=read_html(x)
x=readLines(link[2])
x=html(x)
x
x=GET(link[1])
x=GET(sublink[1])
x=html(x)
x=read_html(x)
x=read_xml(x)
x=xml(x)
x=html(x)
x=GET(sublink[1])
x=html(x)
y=html_nodes(x,'.read_body')
te=html_text(x)
te
te
te=html_text(x)
te
te=html_text(y)
te
k=c()
k[1]=te
x=GET(sublink[2])
x=html(x)
x=read_html(sublink[2])
x=GET(sublink[3])
x=c()
for (i in length(sublink)){
x[i]=readLines(sublink[i])
#a= GET(link[i])
#a=html(a)
#x[i]=html_text
}
x
x=list()
for (i in length(sublink)){
x[i]=readLines(sublink[i])
#a= GET(link[i])
#a=html(a)
#x[i]=html_text
}
x
x=content(GET(sublink[2]))
x=content(GET(sublink[2],Encoding('utf-8')))
k[1]
x=read_html(sublink[2])
x=read_html(sublink[2],encoding = 'utf-8')
x=readLines(sublink[2],encoding = 'utf-8')
x=html(x)
print("<tr class=\"\">")
rm(list=ls())
#보도자료 사이트
url="https://www.kha.or.kr/board/dept/list?siteGb=HOME&siteCd=HOME&rMnuGb=IMP&brdMstIdx=27&menuIdx=446"
if(!require(dplyr)) install.packages("dplyr"); library(dplyr)
if(!require(rvest)) install.packages("rvest"); library(rvest)
if(!require(stringr)) install.packages("stringr"); library(stringr)
if(!require(httr)) install.packages("httr"); library(httr)
cont = read_html(url)
cont = read_html(url)
#보도자료 사이트
url="https://www.kha.or.kr/board/dept/list"
rm(list=ls())
if(!require(RSelenium)) install.packages("RSelenium"); library(RSelenium)
if(!require(RSelenium)) install.packages("RSelenium"); library(RSelenium)
pJs = wdman::phantomjs(port=4567L)
url="http://www.dbpia.co.kr/SearchResult/AdvancedSearch?AdvancedSearchType=TOTAL&Collection=0&SearchMethod=2&SearchOption=0&SearchKeyword=%EB%B3%91%EC%9B%90%EA%B0%90%EC%97%BC&SearchOper=1&category=002008&language=154001&PublishDate=11"
x=read_html(url)
y=html_nodes(x,'.contents-warp')
y=html_nodes(y,'.titleWarp')
y
z=html_text(y)
z
x=read_html(url)
#y=html_nodes(x,'.contents-warp')
y=html_nodes(url,'.titleWarp')
#y=html_nodes(x,'.contents-warp')
y=html_nodes(x,'.titleWarp')
y
title=read_html(url)%>% html_nodes('.titleWarp')%>%html_text
title
textlink=x%>%html_nodes('.btnText')%>%html_nodes('a')
textlink
textlink=x%>%html_nodes('.btnText')
textlink
x=read_html(url)
textlink=x%>%html_nodes('.btnText')%>%html_nodes('a')
textlink
textlink=x%>%html_nodes('.btnText')
textlink=x%>%html_nodes('.contentsWrap')
textlink
title
x=read_html(url)
title=x%>% html_nodes('.titleWarp')%>%html_text
title
textlink=x%>%html_nodes('.contentsWarp')%>%html_nodes('.btnText')%>%html_nodes('a')
textlink
textlink=x%>%html_nodes('.contentsWarp')
textlink
textlink=x%>%html_nodes('.contentsWarp')%>%html_nodes('.btnText')
textlink
textlink=x%>%html_nodes('.contentsBtnWarp')%>%html_nodes('.btnText')
textlink
textlink=x%>%html_nodes('.contentsBtnWarp')%>%html_nodes('li.class')
textlink
textlink=x%>%html_nodes('.contentsBtnWarp')
textlink
url="http://www.hollys.co.kr/store/korea/korStore.do"
# 2-1. 네이버 뉴스 크롤링
url="http://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=102"
cont = read_html(url)
#install.packages("rvest")
library(rvest)
# 2-1. 네이버 뉴스 크롤링
url="http://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=102"
cont = read_html(url)
subcont = html_nodes(cont, '.lnb_today')
subcont1
subcont = html_nodes(cont, '.lnb_today')
subcont1 = html_nodes(subcont, 'a')
subcont2 = html_attr(subcont1, 'href')
subcont2
u="https://movie.naver.com/movie/bi/mi/point.nhn?code=163533#tab"
x=read_html(u)
x=html_nodes(x,'.star_score')
x
x=html_nodes(x,'.input_netizen')
x
x=read_html(u)
x=html_nodes(x,'.input_netizen')
x
url = "https://movie.naver.com/movie/bi/mi/point.nhn?code=163533#tab"
cont = read_html(url)
sub = html_nodes(cont, '.input_netizen')
sub
sub = html_nodes(cont, '.input_netizen')
cont
sub = html_nodes(cont, '.ul')
sub
sub = html_nodes(cont, '.input_netizen ')
sub
sub = html_nodes(cont, 'div')
sub
sub = html_nodes(cont, '.star_score')
sub
sub = html_nodes(cont, 'ul')
sub
sub = html_attr(cont, '.input_netizen')
sub
sub = html_nodes(cont, 'ul')
sub = html_nodes(cont, '.score_result')
sub
sub1 = html_nodes(sub, '.star_score')
sub1
score=html_text(sub1)
score
score=html_nodes(sub1,'em')
score
url = "https://movie.naver.com/movie/bi/mi/point.nhn?code=163533#tab"
cont = read_html(url)
sub = html_nodes(cont, '.score_result')
sub
sub1 = html_nodes(sub, '.star_score')
sub1
sub = html_nodes(cont, '.input_netizen')
source('C:/Users/eunse/Desktop/medical cr/1st.R', echo=TRUE)
url = "https://movie.naver.com/movie/bi/mi/point.nhn?code=163533#tab"
cont = read_html(url)
sub = html_nodes(cont, '.input_netizen')
sub
sub = html_node(cont, '.input_netizen')
sub
library(dplyr)
sub = html_nodes(cont,'body')
sub
sub = html_nodes(cont,'body')%>% html_nodes(cont, '.input_netizen')
sub = html_nodes(cont,'body')%>% html_nodes( '.input_netizen')
sub
sub = html_nodes(cont,'body')%>% html_nodes( '.input_netizen ')
sub
sub1 = html_nodes(cont, '.star_score')
sub1
sub = html_nodes(cont,'score_result')
sub
sub = html_nodes(cont,'.score_result')
sub
sub1 = html_nodes(sub, '.star_score')
sub1
sub = html_nodes(cont,'.score_result')
sub1 = html_nodes(sub, '.ul')
sub1
sub
sub = html_nodes(cont,'.input_netizen')
sub
sub = html_nodes(cont,'.input_netizen\ ')
sub
sub = html_nodes(cont,'.score_result')
sub
url = "https://movie.naver.com/movie/bi/mi/point.nhn?code=163533#tab"
cont = read_html(url)
sub = html_nodes(cont,'.score_result')
sub1 = html_nodes(sub, 'em')
sub1
url = "https://movie.naver.com/movie/bi/mi/point.nhn?code=163533#tab"
cont = read_html(url)
sub = html_nodes(cont,'.score_result')
sub1 = html_nodes(sub, 'em')
sub1
cont = readLines(url)
cont = read_html(url)
sub = html_nodes(url,'.score_reple')
cont = read_html(url)
sub = html_nodes(url,'.score_reple')
rm(list=ls())
if(!require(dplyr)) install.packages("dplyr"); library(dplyr)
if(!require(rvest)) install.packages("rvest"); library(rvest)
if(!require(stringr)) install.packages("stringr"); library(stringr)
url="https://search.naver.com/search.naver?sm=tab_dts&where=news&query=+%22%EB%B3%91%EC%9B%90%22+%22%ED%99%98%EC%9E%90%EC%95%88%EC%A0%84%22+-%22%EC%8B%A0%EC%A0%9C%ED%92%88+%EC%B6%9C%EC%8B%9C%22+-%EC%8B%A0%EA%B8%B0%EC%88%A0+-%ED%8C%8C%EC%97%85+-%EB%B3%B4%ED%97%98+-%EC%B9%98%EB%A7%A4+-%EC%BC%80%EC%9D%B4%ED%81%AC+-%ED%8F%AD%ED%96%89+-%EB%9D%BC%EC%9D%B4%ED%94%84+-%EB%B0%98%EB%A0%A4%EA%B2%AC+-%ED%97%8C%ED%98%88+-%EB%AF%B8%EC%9A%A9+-%EC%BB%A8%EC%84%A4%ED%8C%85+&oquery=%2B%ED%99%98%EC%9E%90%EC%95%88%EC%A0%84%EB%B2%95+-%ED%8C%8C%EC%97%85+-%EB%B3%B4%ED%97%98+-%EC%B9%98%EB%A7%A4+-%EC%BC%80%EC%9D%B4%ED%81%AC+-%ED%8F%AD%ED%96%89+-%EB%9D%BC%EC%9D%B4%ED%94%84+-%EB%B0%98%EB%A0%A4%EA%B2%AC+-%ED%97%8C%ED%98%88+-%EB%AF%B8%EC%9A%A9+-%EC%BB%A8%EC%84%A4%ED%8C%85+-%22%EC%8B%A0%EC%A0%9C%ED%92%88+%EC%B6%9C%EC%8B%9C%22+-%22%EC%8B%A0%EA%B8%B0%EC%88%A0+%EA%B0%9C%EB%B0%9C%22&tqi=TIkROspySEKssZwJ%2BIsssssstg0-501000&qdt=1"
cont = read_html(url)
subcont = html_nodes(cont, '.type01')
subc= html_nodes(subcont, 'dt')
subcont1 = html_nodes(subc, 'a')
subcont2 = html_attr(subcont1, 'href')
title = html_text(subcont1)
title
rm(list=ls())
if(!require(dplyr)) install.packages("dplyr"); library(dplyr)
if(!require(rvest)) install.packages("rvest"); library(rvest)
if(!require(stringr)) install.packages("stringr"); library(stringr)
url="http://www.dbpia.co.kr/SearchResult/AdvancedSearch?AdvancedSearchType=TOTAL&Collection=0&SearchMethod=2&SearchOption=0&SearchKeyword=%EB%B3%91%EC%9B%90%EA%B0%90%EC%97%BC&SearchOper=1&category=002008&language=154001&PublishDate=11"
x=read_html(url)
title=x%>% html_nodes('.titleWarp')%>%html_text
textlink=x%>%html_nodes('.contentsBtnWarp')%>%html_nodes('li.class')%>%html_nodes('a')
title
textlink
textlink=x%>%html_nodes('.listWarp')
textlink
textlink=x%>%html_nodes('.listWarp')%>%html_nodes('.btnText')
textlink
k=x%>%html_nodes('.btnText')
k
k=x%>%html_attrs('.btnText')
textlink=x%>%html_nodes('.listWarp')%>%html_nodes('ul')
textlink
p=textlink%>%html_nodes('.btnText')
p
textlink=x%>%html_nodes('.listWarp')%>%html_nodes('dl')%>%html_nodes('ul')
textlink
p=textlink%>%html_nodes('.btnText')
p
p=textlink%>%html_attr('.btnText')
p
textlink
View(ul)
View(textlink)
p=textlink%>%html_nodes('li')
p
l=p%>%html_attr('.btnText')
l
l=p%>%html_nodes('.btnText')
l
p
p
jungong=c(39, 33, 35.3, 55.5, 52.5, 57.5)
date = c('17/11/25','18/04/28', '18/06/02','18/06/23','18/09/05', '18/09/19')
df = data.frame(date,jungong)
View(df)
df[date]
df[,1]
typeof(df[,1])
class(df[,1])
plot(df[,1],df[,2])
hist(df[,1],df[,2],m)
library(ggplot2)
ggplot(data=df,aes(x=date,y=jungong))
ggplot(data=df,aes(x=date,y=jungong))+geom_point()
date = c('17/11/25','18/04/28', '18/06/02','18/06/23','18/09/05', '18/09/19')+ylim(30,80)
date = c('17/11/25','18/04/28', '18/06/02','18/06/23','18/09/05', '18/09/19')
ggplot(data=df,aes(x=date,y=jungong))+geom_point()+ylim(30,80)
ggplot(data=df,aes(x=date,y=jungong))+geom_point()+ylim(30,70)
ggplot(data=df,aes(x=date,y=jungong))+geom_line()+ylim(30,70)
ggplot(data=df,aes(x=date,y=jungong))+geom_line() #+ylim(30,70)
ggplot(data=df,aes(x=date,y=jungong))+geom_line()+geom_point() #+ylim(30,70)
df
ggplot(data=df,aes(x=date,y=jungong))+geom_line()+geom_point() #+ylim(30,70)
ggplot(data=df,aes(x=date,y=jungong,group =1))+geom_line()+geom_point() #+ylim(30,70)
ggplot(data=df,aes(x=date,y=jungong,group =1))+geom_line()+geom_point() +ylim(30,70)
colnames(df)
colnames(df)[2]='score'
colnames(df)[2]='score'
colnames(df)
ggplot(data=df,aes(x=date,y=score,group =1))+geom_line(color='pink')+geom_point(color='pink') +ylim(30,70)
ggplot(data=df,aes(x=date,y=score,group =1))+geom_line(color='red')+geom_point(size = 21,color='pink') +ylim(30,70)
ggplot(data=df,aes(x=date,y=score,group =1))+geom_line(color='red')+geom_point(size = 10,color='pink') +ylim(30,70)
ggplot(data=df,aes(x=date,y=score,group =1))+geom_line(color='red')+geom_point(size = 6,color='pink') +ylim(30,70)
ggplot(data=df,aes(x=date,y=score,group =1))+geom_line(color='red')+geom_point(size = 6,color='pink',shape = '★') +ylim(30,70)
ggplot(data=df,aes(x=date,y=score,group =1))+geom_line(color='red')+geom_point(size = 10,color='blue',shape = '★') +ylim(30,70)
ggplot(data=df,aes(x=date,y=score,group =1))+geom_line(color='red')+geom_point(size = 7,color='blue',shape = '★') +ylim(30,70)
ggplot(data=df,aes(x=date,y=score,group =1))+geom_line(color='red')+geom_point(size = 7,color='hotpink',shape = '★') +ylim(30,70)
rm(list=ls())
url="http://www.dbpia.co.kr/SearchResult/AdvancedSearch?AdvancedSearchType=TOTAL&Collection=0&SearchMethod=2&SearchOption=0&SearchKeyword=%EB%B3%91%EC%9B%90%EA%B0%90%EC%97%BC&SearchOper=1&category=002008&language=154001&PublishDate=4&PublishSttDate=2014&PublishEndDate=2018"
if(!require(dplyr)) install.packages("dplyr"); library(dplyr)
if(!require(rvest)) install.packages("rvest"); library(rvest)
if(!require(stringr)) install.packages("stringr"); library(stringr)
x=read_html(url)
title=x%>% html_nodes('.titleWarp')%>%html_text
#title = title[-index]
l= c()
for (m in 1:length(title)){
l[m] = strsplit(title[m],'\r\n')[[1]][1]
}
l=gsub('\u00a0','',l)
title = l
title
rm(list=ls())
url="http://www.dbpia.co.kr/SearchResult/AdvancedSearch?AdvancedSearchType=TOTAL&Collection=0&SearchMethod=2&SearchOption=0&SearchKeyword=%EC%9D%98%EB%A3%8C%EA%B8%B0%EA%B8%B0+%EA%B2%B0%ED%95%A8&SearchOper=2&SearchOption=0&SearchKeyword=%EC%9D%98%EB%A3%8C%EC%9E%A5%EB%B9%84+%EA%B2%B0%ED%95%A8&SearchOper=2&SearchOption=0&SearchKeyword=%EC%9D%98%EB%A3%8C%EA%B8%B0%EA%B8%B0+%EC%98%A4%EB%A5%98&SearchOper=2&SearchOption=0&SearchKeyword=%EC%9D%98%EB%A3%8C%EC%9E%A5%EB%B9%84+%EC%98%A4%EB%A5%98&category=002008&language=154001&PublishDate=4&PublishSttDate=2014&PublishEndDate=2018&SrvYN=Y"
if(!require(dplyr)) install.packages("dplyr"); library(dplyr)
if(!require(rvest)) install.packages("rvest"); library(rvest)
if(!require(stringr)) install.packages("stringr"); library(stringr)
x=read_html(url)
title=x%>% html_nodes('.titleWarp')%>%html_text
#title = title[-index]
l= c()
for (m in 1:length(title)){
l[m] = strsplit(title[m],'\r\n')[[1]][1]
}
l=gsub('\u00a0','',l)
title = l
title
sub=x%>%html_nodes('.content01Warp')%>%html_text
sub
id=seq(1,6,3)
author=sub[id]
author = str_extract_all(author, "[가-힣]+")
q=c()
for (i in 1:length(author)){
q[i]=paste(author[[i]], collapse = ',')
}
author=q
author
source_date=sub[id+1]
source = str_extract_all(source_date, "[가-힣]+")
q=c()
for (i in 1:length(source)){
q[i]=paste(source[[i]], collapse = ',')
}
source=q
date=c()
for (i in 1:length(source_date)){
date[i] = strsplit(source_date[[i]],",")[[1]][3]
}
date
dtext=x%>%html_nodes('.btnText') %>%html_nodes('a')%>%html_attr('href')
dte=str_extract_all(dtext,'[0-9]')
subnum=c()
for(i in 1:length(dte)){
subnum[i] = paste0(dte[[i]],collapse = '')
}
sublink=c()
suburl="http://www.dbpia.co.kr/Journal/TextViewNew?id=NODE"
suburl2="&prevPathCode="
for (i in 1:length(subnum)){
sublink[i]=paste0(suburl,subnum[i],suburl2,collapse = '')
}
sublink
text = c()
for(i in 1:length(sublink)){
f = read_html(sublink[i])
text[i] = f%>%html_node('xmp')%>%html_text
}
te=c()
for (i in 1:length(text)){
te[i] = paste(str_extract_all(text[i],"[가-힣]+")[[1]],collapse = ' ')
}
length(te)
df = data.frame(title,author,source,date,te)
getwd()
setwd("C:/Users/eunse/Desktop/medical cr/Dbpia")
dir()
write.csv(df,'의료기기_의료장비plus결함_오류.csv',row.name = FALSE)
write.csv(df,'의료기기_의료장비plus결함_오류.csv',row.names = FALSE)
